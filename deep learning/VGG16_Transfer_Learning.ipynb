{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of VGG16-self.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZFydd8sgYLKGzbo2GPhf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvircohen0/Machine-Learning-Algorithms-From-Scratch/blob/main/VGG16_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSceSaBVBVpo"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping ,TensorBoard\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "!pip install split-folders\n",
        "import splitfolders \n",
        "from keras.models import load_model\n",
        "from distutils.dir_util import copy_tree\n",
        "from google.colab import files \n",
        "import glob\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFRfX6sOpjar"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# download the cats and dogs dataset from Kaggle\n",
        "!kaggle datasets download -d birajsth/cats-and-dogs-filtered\n",
        "# unzip the dataset file\n",
        "!unzip /content/cats-and-dogs-filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi4ZoBdQTDEI"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVSArhJaElaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d956e30c-9716-497e-c33e-ee0c6e86f3e4"
      },
      "source": [
        "# combine the train and validation folders in order to create test, train, validation folders\n",
        "fromDirectory = \"/content/cats_and_dogs_filtered/validation\"\n",
        "toDirectory = \"/content/cats_and_dogs_filtered/train\"\n",
        "copy_tree(fromDirectory, toDirectory)\n",
        "#split the combined folder into test, train, validation folders\n",
        "splitfolders.ratio(\"/content/cats_and_dogs_filtered/train\", output=\"Dataset\", seed=1337, ratio=(.7, .15, .15), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 3000 files [00:00, 8106.76 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQBHbuagq1VE",
        "outputId": "45417052-df87-4715-c67e-299f97b6a05c"
      },
      "source": [
        "# create log directory in for using tensorboard\n",
        "log_dir='logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "\n",
        "# build the train generator to load and augment the images\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=40,\n",
        "                                 width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2,\n",
        "                                 shear_range=0.2,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode=\"nearest\",\n",
        "                                 preprocessing_function=preprocess_input)\n",
        "train_generator=train_datagen.flow_from_directory(r\"/content/Dataset/train\",\n",
        "                                                  target_size=(150,150),color_mode=\"rgb\",\n",
        "                                                  batch_size=16,class_mode=\"categorical\")\n",
        "\n",
        "# build the validation generator \n",
        "val_datagen=ImageDataGenerator(rescale=1./255,preprocessing_function=preprocess_input)\n",
        "val_generator=val_datagen.flow_from_directory(r\"/content/Dataset/val\",\n",
        "                                                  target_size=(150,150),color_mode=\"rgb\",\n",
        "                                                  batch_size=16,class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2100 images belonging to 2 classes.\n",
            "Found 450 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av3lYKgGs44g",
        "outputId": "0c30c562-fed7-4ab0-bdd3-c61abc884264"
      },
      "source": [
        "# using transfer learning on the VGG16 network with imagenet weights\n",
        "base_model=VGG16(weights=\"imagenet\",include_top=False,input_shape=(150,150,3))\n",
        "#calculate the step per epoch size\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "print(\"step size train:\",step_size_train)\n",
        "step_size_val=val_generator.n//val_generator.batch_size\n",
        "print(\"step size test:\",step_size_val)\n",
        "\n",
        "VGG16_self=Sequential()\n",
        "VGG16_self.add(base_model)\n",
        "VGG16_self.add(Flatten())\n",
        "VGG16_self.add(Dense(64,activation=\"relu\"))\n",
        "VGG16_self.add(Dense(2,activation=\"softmax\"))\n",
        "# only the added layers going to train \n",
        "base_model.trainable=False\n",
        "VGG16_self.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "# callbacks for saving the best model, early stopping and tensorboard\n",
        "callbacks = [\n",
        "ModelCheckpoint(str(datetime.datetime.now())+\"_vgg16.h5\",\n",
        "                monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "                save_weights_only=False, mode='auto', save_freq='epoch'),\n",
        "EarlyStopping(monitor='val_accuracy', min_delta=0, patience=3, verbose=1, mode='auto'),\n",
        "tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "step size train: 131\n",
            "step size test: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBbR620rFsEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efe8c0c-dd8b-4016-9644-5fbab91f38ff"
      },
      "source": [
        "# train the model\n",
        "VGG16_self.fit(train_generator,\n",
        "                    steps_per_epoch=step_size_train,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=step_size_val,\n",
        "                     callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "131/131 [==============================] - 26s 139ms/step - loss: 0.8028 - accuracy: 0.6567 - val_loss: 0.2750 - val_accuracy: 0.9040\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.90402, saving model to 2021-02-24 14:54:49.598733_vgg16.h5\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 18s 135ms/step - loss: 0.3699 - accuracy: 0.8310 - val_loss: 0.2280 - val_accuracy: 0.9085\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.90402 to 0.90848, saving model to 2021-02-24 14:54:49.598733_vgg16.h5\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 18s 134ms/step - loss: 0.3111 - accuracy: 0.8661 - val_loss: 0.2207 - val_accuracy: 0.9040\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.90848\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 18s 136ms/step - loss: 0.3023 - accuracy: 0.8758 - val_loss: 0.2448 - val_accuracy: 0.8884\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.90848\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 18s 136ms/step - loss: 0.3227 - accuracy: 0.8548 - val_loss: 0.1970 - val_accuracy: 0.9174\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90848 to 0.91741, saving model to 2021-02-24 14:54:49.598733_vgg16.h5\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 18s 137ms/step - loss: 0.2928 - accuracy: 0.8755 - val_loss: 0.2047 - val_accuracy: 0.9263\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.91741 to 0.92634, saving model to 2021-02-24 14:54:49.598733_vgg16.h5\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 18s 137ms/step - loss: 0.2706 - accuracy: 0.8877 - val_loss: 0.1988 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.92634\n",
            "Epoch 8/10\n",
            "131/131 [==============================] - 18s 137ms/step - loss: 0.2750 - accuracy: 0.8903 - val_loss: 0.2033 - val_accuracy: 0.9129\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.92634\n",
            "Epoch 9/10\n",
            "131/131 [==============================] - 18s 137ms/step - loss: 0.2515 - accuracy: 0.8999 - val_loss: 0.1903 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.92634\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62f0745fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhnFPN6uGSGd",
        "outputId": "417ab17d-02ed-47fd-859d-7d604c65cf29"
      },
      "source": [
        "# load the best model\n",
        "model = load_model(glob.glob('./*.h5')[0])\n",
        "# build the the test generator\n",
        "test_datagen=ImageDataGenerator(rescale=1./255,preprocessing_function=preprocess_input)\n",
        "test_generator=test_datagen.flow_from_directory(r\"/content/Dataset/test\",\n",
        "                                                  target_size=(150,150),color_mode=\"rgb\",\n",
        "                                                  batch_size=1,class_mode=\"categorical\")\n",
        "# evaluate the model on a unseen data\n",
        "scoreSeg = model.evaluate(test_generator)\n",
        "print(\"Model Test accuracy: \",scoreSeg[1])\n",
        "print(\"Model Test Loss: \",scoreSeg[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 450 images belonging to 2 classes.\n",
            "450/450 [==============================] - 4s 8ms/step - loss: 0.2067 - accuracy: 0.9178\n",
            "Model Test accuracy:  0.9177777767181396\n",
            "Model Test Loss:  0.20666751265525818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OwozyOuYa3n"
      },
      "source": [
        "#load tensor board\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_bayes_spam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnvfcHKIswJxd1VI3PVRyi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvircohen0/Machine-Learning-Algorithms-From-Scratch/blob/main/naive_bayes_spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quiapC1eFtIv"
      },
      "source": [
        "!wget http://openclassroom.stanford.edu/MainFolder/courses/MachineLearning/exercises/ex6materials/ex6DataEmails.zip\n",
        "!unzip /content/ex6DataEmails.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CH_YymLFDUc"
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmcrrrtcLp9X"
      },
      "source": [
        "class Vocabulary():\n",
        "\n",
        "  def __init__(self, folder_path):\n",
        "    self.folder_path = folder_path\n",
        "    self.word2count={}\n",
        "    self.wordprob={}\n",
        "    self.num_sent = 0\n",
        "    self.smoothing = 1e-100\n",
        "    self.path_to_list()\n",
        "    self.fill_matrix()\n",
        "\n",
        "# read file into list of words\n",
        "  def file_to_word_list(self,file_path):\n",
        "    a_file = open(file_path,'r')\n",
        "    for line in a_file:\n",
        "      stripped = line.strip()\n",
        "      lower = stripped.lower()\n",
        "      line_list = lower.split()\n",
        "    return line_list\n",
        "\n",
        "# read files from path\n",
        "  def path_to_list(self):\n",
        "    files = os.listdir(self.folder_path)\n",
        "    self.list_of_lists =[]\n",
        "    for file in files:\n",
        "      full_path = os.path.join(self.folder_path,file)\n",
        "      self.list_of_lists.append(self.file_to_word_list(full_path))\n",
        "\n",
        "# count word\n",
        "  def add_word(self, word):\n",
        "      if word not in self.word2count:\n",
        "          self.word2count[word] = 1\n",
        "      else:\n",
        "          self.word2count[word] += 1\n",
        "\n",
        "# add words from sentence\n",
        "  def add_sentence(self, sentence):\n",
        "    self.num_sent +=1\n",
        "    for word in sentence:\n",
        "      self.add_word(word)\n",
        "\n",
        "# return prob for word\n",
        "  def word_probs(self):\n",
        "    self.total_words = sum(self.word2count.values())\n",
        "    for word in self.word2count:\n",
        "      self.wordprob[word] = self.word2count[word]/self.total_words\n",
        "\n",
        "# fill prob list\n",
        "  def fill_matrix(self):\n",
        "    for mail in self.list_of_lists:\n",
        "      self.add_sentence(mail)\n",
        "    self.word_probs()\n",
        "\n",
        "# predict prob of sentence\n",
        "  def predict_prob(self, file_path):\n",
        "    sent = self.file_to_word_list(file_path)\n",
        "    prob=0\n",
        "    for word in sent:\n",
        "      if word in self.wordprob:\n",
        "        prob += np.log1p(self.wordprob[word])\n",
        "      else: prob += self.smoothing\n",
        "    return prob"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEG3Rhv4_7YK",
        "outputId": "6717d00b-1239-44eb-edec-fcabbea9d475"
      },
      "source": [
        "import glob\n",
        "\n",
        "spam = Vocabulary(folder_path ='/content/spam-train')\n",
        "ham = Vocabulary(folder_path ='/content/nonspam-train')\n",
        "\n",
        "spam_test_files = glob.glob('/content/spam-test/*.txt')\n",
        "ham_test_files = glob.glob('/content/nonspam-test/*.txt')\n",
        "\n",
        "test_files = spam_test_files + ham_test_files\n",
        "y_true = np.hstack((np.zeros(len(spam_test_files)),\n",
        "                    np.ones(len(ham_test_files))))\n",
        "\n",
        "spam_prior = np.log1p(spam.num_sent/(spam.num_sent + ham.num_sent))\n",
        "ham_prior = np.log1p(ham.num_sent/(spam.num_sent + ham.num_sent))\n",
        "\n",
        "\n",
        "count = 0\n",
        "for i in range(len(y_true)):\n",
        "  spam_prob = spam.predict_prob(test_files[i]) + spam_prior\n",
        "  ham_prob = ham.predict_prob(test_files[i]) + ham_prior\n",
        "  prediction = np.argmax([spam_prob,ham_prob])\n",
        "  if prediction == y_true[i]:\n",
        "    count+=1\n",
        "\n",
        "print('accuracy score {:.2%}'.format(count/len(y_true)))"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score 90.00%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}